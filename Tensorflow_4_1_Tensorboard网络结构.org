* Tensorflow_4_Tensorboard

epoch_decay learning rate. 随着epoch次数逐渐减小的 learning rate 防止出现
learning rate [步幅过大] 不断从最低点跨过(从左跨到右,又从右跨到左)的情况出现.

learning rate 可以设置为一个 Variable, 然后在每次 epoch 开始时, 通过
~tf.run(tf.assign(lr, lr_init*(0.95**epoch)))~ 来更新.



* Tensorboard 显示网络结构

代码架构
#+BEGIN_SRC ipython :tangle yes :noweb yes :session lec2-simple-MNIST :exports code :async t :results raw drawer
  <<包导入>>

  <<数据准备>>
  # numpy构造(with/without noise)
  # 从已有数据集导入内存

  <<图参数>>
  # 批次大小, 批次数量
  # dropout 保留率
  <<图构造>>
  # 一模: NN layers, name_scope for TB
  # 两函: err fn(单点错误), loss fn(整体错误)
  # 两器: 初始化器, 优化器
  # 准确率计算

  <<图计算>>
  # 运行两器
  # 获得准确率
  # summary Writer for TB
  # 绘图
#+END_SRC


  #+BEGIN_SRC ipython -n :tangle yes :session lec4-tensorboard :exports code :async t :results raw drawer
  import tensorflow as tf
  from tensorflow.examples.tutorials.mnist import input_data

  # 载入数据
  mnist = input_data.read_data_sets("MNIST", one_hot=True)

  # 设置批次大小
  batch_size = 100
  # 计算共有多少批次
  n_batch = mnist.train.num_examples // batch_size

  # TB:想在TB把某几个node放在一起显示为一个整体模块, 要把他们置于一个命名空间
  with tf.name_scope('input'):                            #  (ref:name_scope)
      # 定义两个 placeholder <<< 需要调整到 name_scope 下
      x = tf.placeholder(tf.float32, [None, 784], name='x-input')
      y = tf.placeholder(tf.float32, [None, 10], name='y-input')


  # TB:想在TB把某几个node放在一起显示为一个整体模块, 要把他们置于一个命名空间
  with tf.name_scope('layer'):
      # 创建简单神经网络(无隐藏层)
      with tf.name_scope('wights'):
          W = tf.Variable(tf.zeros([784, 10]), name='W')
      with tf.name_scope('bias'):
          b = tf.Variable(tf.zeros([10]), name='bias')
      with tf.name_scope('score'):
          score = tf.matmul(x, W) + b
      with tf.name_scope('softmax'):
          prediction = tf.nn.softmax(score)

  # 二函,二器
  init = tf.global_variables_initializer()
  optimizer = tf.train.GradientDescentOptimizer(0.2)
  loss = tf.reduce_mean(tf.square(y-prediction))
  train = optimizer.minimize(loss)

  # 预测对错存在一个向量中
  correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction, 1)) # (ref:count correct prediction)
  # 计算准确率
  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

  # 图计算
  with tf.Session() as sess:
      sess.run(init)
      # TB: 这里需要添加一个 writer
      writer = tf.summary.FileWriter('/home/yiddi/git_repos/on_ml_tensorflow/logs/', sess.graph) #   (ref:writer)
      writer.close()
      # 采取训练一轮就测试一轮的方式
      for epoch in range(2):
          # 训练模型
          acc_train = 0
          for batch in range(n_batch):
              batch_xs, batch_ys = mnist.train.next_batch(batch_size)
              _, acc_train = sess.run([train, accuracy], feed_dict={x:batch_xs, y:batch_ys})

          # 测试模型
          # 测试集必须使用已经训练完毕的模型
          acc_test = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})
          print("Iter " + str(epoch) + " ,Train:" + str(acc_train) + " ,Test:" + str(acc_test))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[1]:
:END:


#+DOWNLOADED: /tmp/screenshot.png @ 2018-07-30 00:33:23
[[file:Tensorboard 显示网络结构/screenshot_2018-07-30_00-33-23.png]]


[[(name_scope)][TensorBoard使用第一步就是要建立一个命名空间, 其下定义placeholder, 并且赋名.]]


[[(writer)][其次需要在图计算时把图对象写入文档中]]

#+BEGIN_EXAMPLE
                                   文件夹位置
                                     -------
      writer = tf.summary.FileWriter('logs/', sess.graph)    (ref:writer)
                                              ----------
                                              本对话所计算的 graph 对象引用

#+END_EXAMPLE

当你第二次次运行的你 NN 代码的时候, 第一次的 graph 可能还存储在内存中. 这时候使
用 TensorBoard 去观察是两张图叠加到一起的结果.


为了防止图被重复的载入内存, 应按照如下步骤运行:
#+NAME: process-to-avoid-reload-graph
#+BEGIN_SRC ipython :tangle yes :noweb yes :session :exports code :async t :results raw drawer
  # 1. <<get-pid>>
  # 2. <<kill-pid>>
  # 3. <<del-graph-summary>>
  # 4. build, compute graph and write it into summary file
  # 5. <<run-tensorboard>>
#+END_SRC

#+RESULTS: process-to-avoid-reload-graph
:RESULTS:
# Out[1]:
:END:


TODO: It's better to give a ~:var~ to ~get-pid~ which represent the session name
of python src block which used to build and compute graph

#+name: get-pid
#+BEGIN_SRC shell :results outputs
ps -aux | grep "python" | grep -E "(lec4|tensorboard)" | grep -v "grep" | awk '{print $2}'
#+END_SRC

#+RESULTS: get-pid
| 17474 |
| 17480 |


TODO: 这个 kill-pid 只能接受 sequence 类型不能接受单体, 修正使其可以接受单体.
#+name: kill-pid
#+BEGIN_SRC elisp :results outpout :var pid=get-pid
  (defun r1l(tbl)
    (mapcar (lambda (x) (number-to-string (car x))) tbl)
    )
  (mapcar #'shell-command-to-string
          (mapcar (lambda (x) (concat "kill " x)) (r1l pid))))
#+END_SRC

#+RESULTS:
|   |   |   |

#+name: del-graph-summary
#+BEGIN_SRC shell :results output
  rm -rf /home/yiddi/git_repos/on_ml_tensorflow/logs/*
  ls /home/yiddi/git_repos/on_ml_tensorflow/logs
#+END_SRC


TODO:
https://stackoverflow.com/questions/31835337/emacs-org-mode-how-to-run-shell-scripts-with-backgrounded-processes-without-ha

run shell command below in a async manner, the predefined argument ":async t"
not avaiable for shell
#+name: run-tensorboard
#+BEGIN_SRC sh :session YiddiTensorboard :results outputs :async t
tensorboard --logdir=/home/yiddi/git_repos/on_ml_tensorflow/logs
#+END_SRC

#+RESULTS:




#+BEGIN_EXAMPLE
注意 org babel 运行结果如果是一个 table 的话, 每一行作为一个 list, 所有行再组成
一个 list, 所以每一个 table 都是二维 list

| 29968 |
| 29973 | ===> ((29968)(29973))


|  29968 |   2342 |
|  29973 | 234234 | ===> ((29968 2352)(29973 234234)(234234 121))
| 234234 |    121 |
#+END_EXAMPLE


TODO:
org babel + yasnippet + org table 可以做的事情简直太多了, 比如这种
#+BEGIN_SRC ipython :tangle yes :session :exports code :async t :results raw drawer
  for i in range(30):
      <<src-block-name>>
#+END_SRC
可以把这种模式应用到对整个 ML 代码架构的定义和组织上.

比如 table 是可以放置代码名字在上面的, 而且支持 spreadsheet, 可以形成一个 table:

| 参数1 | 参数2 | 参数3 | ... | loss | acc_test | acc_train |
|-------+-------+-------+-----+------+----------+-----------|
|       |       |       |     |      |          |           |

table ===> 散点图(elisp or python 都可以 用来绘制 acc-test acc-train 关系图) 等
等, 甚至还可以写程序根据两者数据的趋势自动调整参数,之后再进行训练.

#+BEGIN_EXAMPLE
      自动调参, 自动训练, 自动绘图 ->-+
         ^                            |
         |                            |
         +----------------------------+
#+END_EXAMPLE
